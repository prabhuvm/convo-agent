Certainly! Let's create an agent that combines text, image, and audio generation models to create a full multimedia story experience. We'll call this agent "MultimediaStoryForge". It will use OpenAI's GPT for text generation, DALL-E for image generation, and gTTS for audio narration.
Here's the complete code:
pythonCopyimport os
from flask import Flask, request, jsonify, send_file
from dotenv import load_dotenv
import openai
import requests
from io import BytesIO
import uuid
from gtts import gTTS
import tempfile

# Load environment variables
load_dotenv()

# Set up OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)

class MultimediaStoryForgeAgent:
    def __init__(self):
        self.prompt_template = """
        You are MultimediaStoryForge, a creative AI storyteller. Your task is to create a short, engaging story based on the user's prompt.
        The story should be approximately 100-150 words long and have a clear beginning, middle, and end.
        After the story, provide a brief description (no more than 20 words) of a single image that captures the essence of the story.

        User Prompt: {user_prompt}

        Story and Image Description:
        """

    def generate_story_and_image_description(self, user_prompt):
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a creative storyteller and image descriptor."},
                    {"role": "user", "content": self.prompt_template.format(user_prompt=user_prompt)}
                ],
                max_tokens=250,
                n=1,
                stop=None,
                temperature=0.8,
            )
            content = response.choices[0].message['content'].strip()
            story, image_description = content.rsplit('\n', 1)
            return story.strip(), image_description.strip()
        except Exception as e:
            return f"An error occurred: {str(e)}", ""

    def generate_image(self, image_description):
        try:
            response = openai.Image.create(
                prompt=image_description,
                n=1,
                size="512x512"
            )
            image_url = response['data'][0]['url']
            image_data = requests.get(image_url).content
            return BytesIO(image_data)
        except Exception as e:
            return f"An error occurred during image generation: {str(e)}"

    def generate_audio(self, text):
        try:
            tts = gTTS(text=text, lang='en')
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
            tts.save(temp_file.name)
            return temp_file.name
        except Exception as e:
            return f"An error occurred during audio generation: {str(e)}"

multimedia_story_forge = MultimediaStoryForgeAgent()

@app.route('/question', methods=['POST'])
def generate_multimedia_story():
    data = request.json
    user_query = data.get('query', '')

    if not user_query:
        return jsonify({"error": "No query provided"}), 400

    story, image_description = multimedia_story_forge.generate_story_and_image_description(user_query)
    image_data = multimedia_story_forge.generate_image(image_description)
    audio_file = multimedia_story_forge.generate_audio(story)

    if isinstance(image_data, str):  # Error occurred
        return jsonify({"error": image_data}), 500
    if audio_file.startswith("An error occurred"):
        return jsonify({"error": audio_file}), 500

    unique_image_filename = f"{uuid.uuid4()}.png"
    with open(unique_image_filename, 'wb') as f:
        f.write(image_data.getvalue())

    unique_audio_filename = f"{uuid.uuid4()}.mp3"
    os.rename(audio_file, unique_audio_filename)

    return jsonify({
        "story": story,
        "image_url": f"/image/{unique_image_filename}",
        "audio_url": f"/audio/{unique_audio_filename}"
    })

@app.route('/image/<filename>')
def serve_image(filename):
    return send_file(filename, mimetype="image/png")

@app.route('/audio/<filename>')
def serve_audio(filename):
    return send_file(filename, mimetype="audio/mp3")

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
To use this code:

Save it as app.py.
Create a .env file in the same directory with your OpenAI API key:
CopyOPENAI_API_KEY=your_openai_api_key_here

Install the required packages:
Copypip install flask python-dotenv openai requests gtts

Run the application:
Copypython app.py


This will start a Flask server on port 5000. You can then send POST requests to http://localhost:5000/question with a JSON body like this:
jsonCopy{
    "query": "A time-traveling detective solving a mystery in ancient Egypt"
}
The server will respond with a JSON object containing the generated story, a URL to access the generated image, and a URL to access the audio narration:
jsonCopy{
    "story": "Detective Jack Chronos stepped out of his time machine...",
    "image_url": "/image/some-unique-id.png",
    "audio_url": "/audio/another-unique-id.mp3"
}
You can then access the image and audio by making GET requests to the provided URLs.
To deploy this as a Python program:

Ensure you have Python installed on your deployment machine.
Copy the app.py and .env files to your deployment location.
Install the required packages as mentioned above.
Run the application using python app.py.

For production deployment:

Use a production WSGI server like Gunicorn: gunicorn -w 4 -b 0.0.0.0:5000 app:app
Implement proper file management (delete image and audio files after a certain time)
Add error handling and logging
Implement rate limiting and other security measures
Consider using a cloud storage service for storing and serving images and audio files

This agent provides a rich, multimedia storytelling experience by generating unique, personalized short stories based on user prompts, creating a visual representation of the story, and providing an audio narration. Users can input any scenario or idea, and the AI will create a tale, illustrate it, and narrate it for them, engaging multiple senses for a more immersive experience.
Would you like me to explain any part of this code in more detail or suggest any enhancements?