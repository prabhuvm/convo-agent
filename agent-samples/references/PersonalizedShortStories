Certainly! Let's create a simple yet entertaining AI agent that generates personalized short stories based on user prompts. We'll call it "StorySpinner". This agent will use OpenAI's GPT model for text generation and will be exposed as a Flask API.
Here's the complete code for this idea:
pythonCopyimport os
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import openai

# Load environment variables
load_dotenv()

# Set up OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)

class StorySpinnerAgent:
    def __init__(self):
        self.prompt_template = """
        You are StorySpinner, a creative AI storyteller. Your task is to create a short, engaging story based on the user's prompt.
        The story should be approximately 100-150 words long and have a clear beginning, middle, and end.

        User Prompt: {user_prompt}

        Story:
        """

    def generate_story(self, user_prompt):
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a creative storyteller."},
                    {"role": "user", "content": self.prompt_template.format(user_prompt=user_prompt)}
                ],
                max_tokens=200,
                n=1,
                stop=None,
                temperature=0.8,
            )
            return response.choices[0].message['content'].strip()
        except Exception as e:
            return f"An error occurred: {str(e)}"

story_spinner = StorySpinnerAgent()

@app.route('/question', methods=['POST'])
def generate_story():
    data = request.json
    user_query = data.get('query', '')

    if not user_query:
        return jsonify({"error": "No query provided"}), 400

    story = story_spinner.generate_story(user_query)
    return jsonify({"story": story})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
To use this code:

Save it as app.py.
Create a .env file in the same directory with your OpenAI API key:
CopyOPENAI_API_KEY=your_openai_api_key_here

Install the required packages:
Copypip install flask python-dotenv openai

Run the application:
Copypython app.py


This will start a Flask server on port 5000. You can then send POST requests to http://localhost:5000/question with a JSON body like this:
{
    "query": "A space adventure with a talking cat"
}
The server will respond with a JSON object containing the generated story.
To deploy this as a Python program:

Ensure you have Python installed on your deployment machine.
Copy the app.py and .env files to your deployment location.
Install the required packages as mentioned above.
Run the application using python app.py.

For production deployment, you might want to use a production WSGI server like Gunicorn:

Install Gunicorn: pip install gunicorn
Run the app using Gunicorn: gunicorn -w 4 -b 0.0.0.0:5000 app:app

Remember to secure your API key and consider implementing rate limiting and other security measures for a production environment.
This simple agent provides an entertaining experience by generating unique, personalized short stories based on user prompts. Users can input any scenario or idea, and the AI will spin a quick tale for them.
Would you like me to explain any part of this code in more detail or suggest any enhancements?